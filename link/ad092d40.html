<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>pytorch nn.Module | 记录收获，重拾旧遗</title><meta name="author" content="独孤白"><meta name="copyright" content="独孤白"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="pytorch nn.Module 12345# 前面有&gt;&gt;&gt; 为代码，没有&gt;&gt;&gt; 为运行结果&gt;&gt;&gt; import torch&gt;&gt;&gt; import torch.nn as nn&gt;&gt;&gt; bn &#x3D; nn.BatchNorm2d(3) 一. 数据类型转换及数据转移方法1.数据转移cpu&#x2F;gpu123456789#">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch nn.Module">
<meta property="og:url" content="http://liumeng.top/link/ad092d40.html">
<meta property="og:site_name" content="记录收获，重拾旧遗">
<meta property="og:description" content="pytorch nn.Module 12345# 前面有&gt;&gt;&gt; 为代码，没有&gt;&gt;&gt; 为运行结果&gt;&gt;&gt; import torch&gt;&gt;&gt; import torch.nn as nn&gt;&gt;&gt; bn &#x3D; nn.BatchNorm2d(3) 一. 数据类型转换及数据转移方法1.数据转移cpu&#x2F;gpu123456789#">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/markdown/202302101913815.png">
<meta property="article:published_time" content="2023-02-08T15:18:56.000Z">
<meta property="article:modified_time" content="2023-12-16T14:37:07.443Z">
<meta property="article:author" content="独孤白">
<meta property="article:tag" content="pytorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/markdown/202302101913815.png"><link rel="shortcut icon" href="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/img/favicon.png"><link rel="canonical" href="http://liumeng.top/link/ad092d40.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'pytorch nn.Module',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-12-16 14:37:07'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = url => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      link.onload = () => resolve()
      link.onerror = () => reject()
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/nav.css"><link rel="stylesheet" href="/css/myStyle.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/img/avatar.jpg" onerror="onerror=null;src='https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">56</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/markdown/202302101913815.png')"><nav id="nav"><span id="blog-info"><a href="/" title="记录收获，重拾旧遗"><span class="site-name">记录收获，重拾旧遗</span></a></span><div id="menus"></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><center id="name-container"><a id="page-name" href="javascript:scrollToTop()">PAGE_NAME</a></center><div id="nav-right"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">pytorch nn.Module</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2023-02-08T15:18:56.000Z" title="发表于 2023-02-08 15:18:56">2023-02-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>16分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="pytorch nn.Module"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/link/ad092d40.html#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/link/ad092d40.html" itemprop="commentCount"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="pytorch-nn-Module"><a href="#pytorch-nn-Module" class="headerlink" title="pytorch nn.Module"></a>pytorch nn.Module</h1><p><img src="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/markdown/202302101913815.png" alt="PyTorch Releases Version 1.7 With New Features Like CUDA 11, New APIs ..."></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 前面有&gt;&gt;&gt; 为代码，没有&gt;&gt;&gt; 为运行结果</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn = nn.BatchNorm2d(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<h2 id="一-数据类型转换及数据转移方法"><a href="#一-数据类型转换及数据转移方法" class="headerlink" title="一. 数据类型转换及数据转移方法"></a>一. 数据类型转换及数据转移方法</h2><h3 id="1-数据转移cpu-gpu"><a href="#1-数据转移cpu-gpu" class="headerlink" title="1.数据转移cpu/gpu"></a>1.数据转移cpu/gpu</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将模型转移到指定的设备中运行，返回值为self</span></span><br><span class="line"><span class="comment"># cpu -- 数据转移到cpu中</span></span><br><span class="line"><span class="comment"># cuda -- 数据转移到gpu中，可通过device指定gpu</span></span><br><span class="line"><span class="comment"># xpu -- 数据转移到xpu中，可通过device指定xpu</span></span><br><span class="line"><span class="comment"># to_empty -- torch后续版本功能，将参数和缓冲区移动到指定设备而不复制存储</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.cpu()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.cuda()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.xpu()</span><br><span class="line">BatchNorm2d(<span class="number">3</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h3 id="2-数据类型转换"><a href="#2-数据类型转换" class="headerlink" title="2.数据类型转换"></a>2.数据类型转换</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将模型的参数转换为指定的类型，均为浮点数的转换，不能转换int类型的数据,返回值为self</span></span><br><span class="line"><span class="comment"># bfloat16 -- 占用更少的空间，但相应的精度下降，更详细的解释https://mp.weixin.qq.com/s/eHeewCAO0noD2d-dXWidMA</span></span><br><span class="line"><span class="comment"># half -- 浮点数类型float16，对比bfloat16占用空间更多，但精度更高</span></span><br><span class="line"><span class="comment"># float -- 浮点数类型float32</span></span><br><span class="line"><span class="comment"># double -- 浮点数类型float64</span></span><br><span class="line"><span class="comment"># type -- 传入参数为数据类型，可进行int和float类型的转换</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.bfloat16()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.half()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.<span class="built_in">float</span>()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.double()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.<span class="built_in">type</span>(torch.<span class="built_in">float</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.<span class="built_in">type</span>(torch.<span class="built_in">int</span>)</span><br><span class="line">BatchNorm2d(<span class="number">3</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 上面是整个模型的方法，下面是数据的方法</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.weight.bfloat16()</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>, dtype=torch.bfloat16,</span><br><span class="line">       grad_fn=&lt;CopyBackwards&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.weight.half()</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>, dtype=torch.float16,</span><br><span class="line">       grad_fn=&lt;CopyBackwards&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.weight.<span class="built_in">float</span>()</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.weight.double()</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>, dtype=torch.float64,</span><br><span class="line">       grad_fn=&lt;CopyBackwards&gt;)</span><br></pre></td></tr></table></figure>
<h3 id="3-通用方法to-args-kwargs"><a href="#3-通用方法to-args-kwargs" class="headerlink" title="3.通用方法to(*args, **kwargs)"></a>3.通用方法to(<em>*args</em>, **kwargs)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 能够修改数据类型以及进行数据转移</span></span><br><span class="line"><span class="comment"># 修改数据类型 to(`数据类型`)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>linear = nn.Linear(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>linear.weight</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[ <span class="number">0.1913</span>, -<span class="number">0.3420</span>],</span><br><span class="line">        [-<span class="number">0.5113</span>, -<span class="number">0.2325</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>linear.to(torch.double)</span><br><span class="line">Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>linear.weight</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[ <span class="number">0.1913</span>, -<span class="number">0.3420</span>],</span><br><span class="line">        [-<span class="number">0.5113</span>, -<span class="number">0.2325</span>]], dtype=torch.float64)</span><br><span class="line"><span class="comment"># 数据转移 to(`gpu/cpu/xpu`,dtype=`数据类型`,non_blocking=True)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>gpu1 = torch.device(<span class="string">&quot;cuda:1&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>linear.to(gpu1, dtype=torch.half, non_blocking=<span class="literal">True</span>)</span><br><span class="line">Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>linear.weight</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[ <span class="number">0.1914</span>, -<span class="number">0.3420</span>],</span><br><span class="line">        [-<span class="number">0.5112</span>, -<span class="number">0.2324</span>]], dtype=torch.float16, device=<span class="string">&#x27;cuda:1&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="二-模型以及网络参数的查看及调整"><a href="#二-模型以及网络参数的查看及调整" class="headerlink" title="二.模型以及网络参数的查看及调整"></a>二.模型以及网络参数的查看及调整</h2><h3 id="1-children和module"><a href="#1-children和module" class="headerlink" title="1.children和module"></a>1.children和module</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 涉及方法有children(),module(),named_children(),named_module()</span></span><br><span class="line"><span class="comment"># 两者都是返回模型的网络结构，但childrens返回的是表层的结构，而modules返回的是一层一层分解的结构</span></span><br><span class="line"><span class="comment"># 例如：有一数组 [1,2,[3,3,4]]</span></span><br><span class="line"><span class="comment"># childerns返回值为：1,2,[3,3,4]</span></span><br><span class="line"><span class="comment"># modules返回值为：[1,2,[3,3,4]],1,2,[3,3,4],3,3,4 若两个3为同一实例则只显示一次</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>conv1 = nn.Conv2d(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mod1 = nn.Sequential(conv1,nn.ReLU(),nn.Sequential(conv1,nn.ReLU()))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> idx,mod <span class="keyword">in</span> <span class="built_in">enumerate</span>(mod1.children()):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="built_in">print</span>(idx,<span class="string">&#x27;--&gt;&#x27;</span>,mod)</span><br><span class="line"><span class="number">0</span> --&gt; Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"><span class="number">1</span> --&gt; ReLU()</span><br><span class="line"><span class="number">2</span> --&gt; Sequential(</span><br><span class="line">  (<span class="number">0</span>): Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">1</span>): ReLU()</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 只展示了最外层的结构</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> idx,mod <span class="keyword">in</span> <span class="built_in">enumerate</span>(mod1.modules()):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="built_in">print</span>(idx,<span class="string">&#x27;--&gt;&#x27;</span>,mod)</span><br><span class="line"><span class="number">0</span> --&gt; Sequential(</span><br><span class="line">  (<span class="number">0</span>): Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">1</span>): ReLU()</span><br><span class="line">  (<span class="number">2</span>): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): ReLU()</span><br><span class="line">  )</span><br><span class="line">)</span><br><span class="line"><span class="number">1</span> --&gt; Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"><span class="number">2</span> --&gt; ReLU()</span><br><span class="line"><span class="number">3</span> --&gt; Sequential(</span><br><span class="line">  (<span class="number">0</span>): Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">1</span>): ReLU()</span><br><span class="line">)</span><br><span class="line"><span class="number">4</span> --&gt; ReLU()</span><br><span class="line"><span class="comment"># 展示每一层的结构</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> idx,mod <span class="keyword">in</span> <span class="built_in">enumerate</span>(mod1.named_children()):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="built_in">print</span>(idx,<span class="string">&#x27;--&gt;&#x27;</span>,mod)</span><br><span class="line"><span class="number">0</span> --&gt; (<span class="string">&#x27;0&#x27;</span>, Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line"><span class="number">1</span> --&gt; (<span class="string">&#x27;1&#x27;</span>, ReLU())</span><br><span class="line"><span class="number">2</span> --&gt; (<span class="string">&#x27;2&#x27;</span>, Sequential(</span><br><span class="line">  (<span class="number">0</span>): Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">1</span>): ReLU()</span><br><span class="line">))</span><br><span class="line"><span class="comment"># 展示最外层的名称及结构</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> idx,mod <span class="keyword">in</span> <span class="built_in">enumerate</span>(mod1.named_modules()):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="built_in">print</span>(idx,<span class="string">&#x27;--&gt;&#x27;</span>,mod)</span><br><span class="line"><span class="number">0</span> --&gt; (<span class="string">&#x27;&#x27;</span>, Sequential(</span><br><span class="line">  (<span class="number">0</span>): Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">1</span>): ReLU()</span><br><span class="line">  (<span class="number">2</span>): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): ReLU()</span><br><span class="line">  )</span><br><span class="line">))</span><br><span class="line"><span class="number">1</span> --&gt; (<span class="string">&#x27;0&#x27;</span>, Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line"><span class="number">2</span> --&gt; (<span class="string">&#x27;1&#x27;</span>, ReLU())</span><br><span class="line"><span class="number">3</span> --&gt; (<span class="string">&#x27;2&#x27;</span>, Sequential(</span><br><span class="line">  (<span class="number">0</span>): Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">1</span>): ReLU()</span><br><span class="line">))</span><br><span class="line"><span class="number">4</span> --&gt; (<span class="string">&#x27;2.1&#x27;</span>, ReLU())</span><br><span class="line"><span class="comment"># 展示每一层的名称及结构</span></span><br></pre></td></tr></table></figure>
<h3 id="2-buffers和parameters"><a href="#2-buffers和parameters" class="headerlink" title="2.buffers和parameters"></a>2.buffers和parameters</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 涉及方法有buffers(),parameters(),named_buffers(),named_parameters()</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i <span class="keyword">in</span> bn.buffers():</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="built_in">print</span>(i)</span><br><span class="line">tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>])</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])</span><br><span class="line">tensor(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 不输出buffers的名称</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i <span class="keyword">in</span> bn.parameters():</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="built_in">print</span>(i)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 不输出parameters的名称</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(bn.named_buffers())</span><br><span class="line">[(<span class="string">&#x27;running_mean&#x27;</span>, tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>])),</span><br><span class="line"> (<span class="string">&#x27;running_var&#x27;</span>, tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])),</span><br><span class="line"> (<span class="string">&#x27;num_batches_tracked&#x27;</span>, tensor(<span class="number">0</span>))]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(bn.named_parameters())</span><br><span class="line">[(<span class="string">&#x27;weight&#x27;</span>,</span><br><span class="line">  Parameter containing:</span><br><span class="line">  tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], requires_grad=<span class="literal">True</span>)),</span><br><span class="line"> (<span class="string">&#x27;bias&#x27;</span>,</span><br><span class="line">  Parameter containing:</span><br><span class="line">  tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>], requires_grad=<span class="literal">True</span>))]</span><br><span class="line"><span class="comment"># 输出名称需要使用named_buffers(),named_parameters()</span></span><br><span class="line"><span class="comment"># 两者唯一的区别是，buffer不需要梯度不被优化，parameter需要梯度可以被优化</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.running_mean.requiers_grad</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.weight.requiers_grad</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="comment"># 上面用batchnorm层来展示区别，但两者都能够看做是attribute</span></span><br><span class="line"><span class="comment"># 导出state_dict</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(bn.state_dict())</span><br><span class="line">[<span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;bias&#x27;</span>, <span class="string">&#x27;running_mean&#x27;</span>, <span class="string">&#x27;running_var&#x27;</span>, <span class="string">&#x27;num_batches_tracked&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h3 id="3-模型结构和数据的增删改"><a href="#3-模型结构和数据的增删改" class="headerlink" title="3.模型结构和数据的增删改"></a>3.模型结构和数据的增删改</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 涉及的方法有add_module(),register_buffers(),register_parameter()</span></span><br><span class="line"><span class="comment"># 添加模型的module</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model = nn.Sequential()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.add_module(<span class="string">&#x27;1&#x27;</span>, nn.Conv2d(<span class="number">12</span>,<span class="number">12</span>,<span class="number">12</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(model)</span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">1</span>): Conv2d(<span class="number">12</span>, <span class="number">12</span>, kernel_size=(<span class="number">12</span>, <span class="number">12</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 添加模型的buffer</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(bn.named_buffers())</span><br><span class="line">[(<span class="string">&#x27;running_mean&#x27;</span>, tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>])),</span><br><span class="line"> (<span class="string">&#x27;running_var&#x27;</span>, tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])),</span><br><span class="line"> (<span class="string">&#x27;num_batches_tracked&#x27;</span>, tensor(<span class="number">0</span>))]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.register_buffer(<span class="string">&#x27;1&#x27;</span>, torch.tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(bn.named_buffers())</span><br><span class="line">[(<span class="string">&#x27;running_mean&#x27;</span>, tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>])),</span><br><span class="line"> (<span class="string">&#x27;running_var&#x27;</span>, tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])),</span><br><span class="line"> (<span class="string">&#x27;num_batches_tracked&#x27;</span>, tensor(<span class="number">0</span>)),</span><br><span class="line"> (<span class="string">&#x27;1&#x27;</span>, tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]))]</span><br><span class="line"><span class="comment"># 添加模型的parameter</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(bn.named_parameters())</span><br><span class="line">[(<span class="string">&#x27;weight&#x27;</span>,</span><br><span class="line">  Parameter containing:</span><br><span class="line">  tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], requires_grad=<span class="literal">True</span>)),</span><br><span class="line"> (<span class="string">&#x27;bias&#x27;</span>,</span><br><span class="line">  Parameter containing:</span><br><span class="line">  tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>], requires_grad=<span class="literal">True</span>))]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.register_parameter(<span class="string">&#x27;2&#x27;</span>,torch.nn.Parameter(torch.tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>])))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(bn.named_parameters())</span><br><span class="line">[(<span class="string">&#x27;weight&#x27;</span>,</span><br><span class="line">  Parameter containing:</span><br><span class="line">  tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], requires_grad=<span class="literal">True</span>)),</span><br><span class="line"> (<span class="string">&#x27;bias&#x27;</span>,</span><br><span class="line">  Parameter containing:</span><br><span class="line">  tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>], requires_grad=<span class="literal">True</span>)),</span><br><span class="line"> (<span class="string">&#x27;2&#x27;</span>,</span><br><span class="line">  Parameter containing:</span><br><span class="line">  tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>], requires_grad=<span class="literal">True</span>))]</span><br><span class="line"><span class="comment"># register_parameter()的参数为torch.nn.Parameter类型</span></span><br><span class="line"><span class="comment"># 在日常的代码开发过程中，更常见的用法是直接通过 self.xxx = xxx 的方式来增加或修改子神经网络模块、parameters、buffers 以及其他一般的 attribute。这种方式本质上会调用 nn.Module 重载的函数 __setattr__ </span></span><br><span class="line"><span class="comment"># 修改bn的weight的数值</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.weight.data = torch.zeros(<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.weight</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 删除某个buffer或parameter,当做attribute删除</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">delattr</span>(bn, <span class="string">&#x27;2&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(bn.named_parameters())</span><br><span class="line">[(<span class="string">&#x27;weight&#x27;</span>,</span><br><span class="line">  Parameter containing:</span><br><span class="line">  tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])),</span><br><span class="line"> (<span class="string">&#x27;bias&#x27;</span>,</span><br><span class="line">  Parameter containing:</span><br><span class="line">  tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]))]</span><br></pre></td></tr></table></figure>
<h3 id="4-模型与梯度初始化"><a href="#4-模型与梯度初始化" class="headerlink" title="4.模型与梯度初始化"></a>4.模型与梯度初始化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 涉及方法有apply(),zero_grad(),requires_grad_()</span></span><br><span class="line"><span class="comment"># apply -- 一般用于初始化模型</span></span><br><span class="line"><span class="comment"># zero_grad -- 将模型所有参数的梯度设置为零</span></span><br><span class="line"><span class="comment"># requires_grad_ -- 梯度启动，梯度禁用，用于冻结某个层</span></span><br><span class="line"><span class="comment"># 将linear层权重全部设为1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">init_weight</span>(<span class="params">m</span>):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="built_in">print</span>(m)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        m.weight.fill_(<span class="number">1.0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="built_in">print</span>(m.weight)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net = nn.Sequential(nn.Linear(<span class="number">2</span>, <span class="number">2</span>), nn.Linear(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net.apply(init_weights)</span><br><span class="line">Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="literal">True</span>)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line">Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="literal">True</span>)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1</span></span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]], requires_grad=<span class="literal">True</span>)   </span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (<span class="number">1</span>): Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (<span class="number">1</span>): Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 根据结果可以看出该方法，首先将网络结构每一层传入分析层的内容，然后将整个网络传入，最后返回整个网络的信息</span></span><br><span class="line"><span class="comment"># 将模型的参数梯度设为0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.zero_grad()    </span><br><span class="line"><span class="comment"># 当在定义一个tensor的时候并且将requires_grad设置为True,这个tensor就拥有自动求梯度    </span></span><br><span class="line"><span class="comment"># 梯度的禁用与启用</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.weight</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.requires_grad_(requires_grad = <span class="literal">False</span>)</span><br><span class="line">BatchNorm2d(<span class="number">3</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.weight</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])</span><br><span class="line"><span class="comment"># 梯度已禁用</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.requires_grad_(requires_grad = <span class="literal">True</span>)</span><br><span class="line">BatchNorm2d(<span class="number">3</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.weight</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 梯度已启用    </span></span><br></pre></td></tr></table></figure>
<h3 id="5-获取指定模型参数的值"><a href="#5-获取指定模型参数的值" class="headerlink" title="5.获取指定模型参数的值"></a>5.获取指定模型参数的值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 涉及的主要方法有 get_buffer(),get_parameter(),get_submodule()</span></span><br><span class="line"><span class="comment"># 旧版本可能无法使用</span></span><br><span class="line"><span class="comment"># 获取指定buffer的值</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.get_buffer(<span class="string">&quot;running_mean&quot;</span>)</span><br><span class="line">tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>])</span><br><span class="line"><span class="comment"># 获取指定parameter的值</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.get_parameter(<span class="string">&quot;weight&quot;</span>)</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 获取指定子模块的值</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mod = nn.Sequential()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mod1 = nn.Sequential(nn.Conv2d(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>),nn.Conv2d(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mod.add_module(<span class="string">&quot;1&quot;</span>,mod1)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mod.get_submodule(<span class="string">&quot;1&quot;</span>)</span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">1</span>): Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="三-模型的训练"><a href="#三-模型的训练" class="headerlink" title="三.模型的训练"></a>三.模型的训练</h2><h3 id="1-前向和反向传播"><a href="#1-前向和反向传播" class="headerlink" title="1.前向和反向传播"></a>1.前向和反向传播</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 虽然模型有forward()方法，但一般forward是定义自己的子类时，必须重写的，是实现各个层之间的连接关系的核心</span></span><br><span class="line"><span class="comment"># 只要在nn.Module的子类中定义了forward函数，backward函数就会利用autograd自动实现</span></span><br><span class="line"><span class="comment"># forward方法，不需要单独调用，直接传入参数后即可自动调用</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(LeNet,self).__init__()</span><br><span class="line">        layer1 = nn.Sequential()</span><br><span class="line">        layer1.add_module(<span class="string">&#x27;conv1&#x27;</span>, nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line">        layer1.add_module(<span class="string">&#x27;pool1&#x27;</span>, nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        self.layer1 = layer1</span><br><span class="line"></span><br><span class="line">        layer2 = nn.Sequential()</span><br><span class="line">        layer2.add_module(<span class="string">&#x27;conv2&#x27;</span>, nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>))</span><br><span class="line">        layer2.add_module(<span class="string">&#x27;pool2&#x27;</span>, nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        self.layer2 = layer2</span><br><span class="line"></span><br><span class="line">        layer3 = nn.Sequential()</span><br><span class="line">        layer3.add_module(<span class="string">&#x27;fc1&#x27;</span>, nn.Linear(<span class="number">400</span>, <span class="number">120</span>))</span><br><span class="line">        layer3.add_module(<span class="string">&#x27;fc2&#x27;</span>, nn.Linear(<span class="number">120</span>, <span class="number">84</span>))</span><br><span class="line">        layer3.add_module(<span class="string">&#x27;fc3&#x27;</span>, nn.Linear(<span class="number">84</span>, <span class="number">10</span>))</span><br><span class="line">        self.layer3 = layer3</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">module = LeNet()</span><br><span class="line">module(x)  </span><br><span class="line"><span class="comment"># 向模型中传入数据即可自动调用forward方法，以及使用自动梯度进行backward </span></span><br></pre></td></tr></table></figure>
<h3 id="2-模型训练和评估"><a href="#2-模型训练和评估" class="headerlink" title="2.模型训练和评估"></a>2.模型训练和评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train(),eval()和torch.no_gard()</span></span><br><span class="line"><span class="comment"># model.train()和model.eval()的区别主要在于Batch Normalization和Dropout两层</span></span><br><span class="line"><span class="comment"># 训练前需要调用train(),测试前需要调用eval()来锁定</span></span><br><span class="line"><span class="comment"># 在train模式下，dropout网络层会按照设定的参数p，设置保留激活单元的概率（保留概率=p)。BN层会继续计算数据的mean和var等参数并更新。</span></span><br><span class="line"><span class="comment"># 在eval模式下，dropout层会让所有的激活单元都通过，而BN层会停止计算和更新mean和var，直接使用在训练阶段已经学出的mean和var值。</span></span><br><span class="line"><span class="comment"># eval模式不会影响各层的gradient计算行为，即gradient计算和存储与training模式一样，只是不进行反向传播（back probagation)。</span></span><br><span class="line"><span class="comment"># with torch.no_grad()则主要是用于停止autograd模块的工作，以起到加速和节省显存的作用。它的作用是将该with语句包裹起来的部分停止梯度的更新，从而节省了GPU算力和显存，但是并不会影响dropout和BN层的行为。</span></span><br><span class="line"><span class="comment"># ps：参考连接：https://blog.csdn.net/qq_38410428/article/details/101102075</span></span><br></pre></td></tr></table></figure>
<h3 id="3-HOOK——获取神经网络特征和梯度的有效工具"><a href="#3-HOOK——获取神经网络特征和梯度的有效工具" class="headerlink" title="3.HOOK——获取神经网络特征和梯度的有效工具"></a>3.HOOK——获取神经网络特征和梯度的有效工具</h3><blockquote>
<p>参考链接：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/69e57e3526b3，https://www.jb51.net/article/240198.htm">https://www.jianshu.com/p/69e57e3526b3，https://www.jb51.net/article/240198.htm</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 涉及的方法有register_forward_hook(),register_forward_pre_hook(),register_backward_hook(),register_full_backward_hook()</span></span><br><span class="line"><span class="comment"># 在模型训练过程中，对于模型的中间模块，可以看做为中间节点，输出为特征图或者激活值，反向传播的梯度值会被自动释放，想要获取他们，需要用到hook功能</span></span><br><span class="line"><span class="comment"># register_forward_hook是获取前向传播的输出的，即特征图或激活值；register_backward_hook是获取反向传播的输出的，即梯度值。</span></span><br><span class="line"><span class="comment"># hook的内部原理比较复杂，但使用简单</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="四-模型的保存读取"><a href="#四-模型的保存读取" class="headerlink" title="四.模型的保存读取"></a>四.模型的保存读取</h2><h3 id="1-模型保存"><a href="#1-模型保存" class="headerlink" title="1.模型保存"></a>1.模型保存</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># state_dict()能够返回模型的参数到一个字典</span></span><br><span class="line"><span class="comment"># 模型的参数保存</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.state_dict()</span><br><span class="line">OrderedDict([(<span class="string">&#x27;weight&#x27;</span>, tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])),</span><br><span class="line">             (<span class="string">&#x27;bias&#x27;</span>, tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>])),</span><br><span class="line">             (<span class="string">&#x27;running_mean&#x27;</span>, tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>])),</span><br><span class="line">             (<span class="string">&#x27;running_var&#x27;</span>, tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])),</span><br><span class="line">             (<span class="string">&#x27;num_batches_tracked&#x27;</span>, tensor(<span class="number">0</span>))])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.save(bn.state_dict(), <span class="string">&quot;mod&quot;</span>)</span><br><span class="line"><span class="comment"># PATH为字符串类型，模型保存在指定路径下</span></span><br><span class="line"><span class="comment"># PS：可以直接保存模型到PATH</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.save(bn, <span class="string">&quot;mod1&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="2-模型加载"><a href="#2-模型加载" class="headerlink" title="2.模型加载"></a>2.模型加载</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load_state_dict()能够读取状态字典的数据并载入模型</span></span><br><span class="line"><span class="comment"># 修改模型中weight的数值</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.weight.data = torch.zeros(<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.weight</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 导入保存好的模型参数</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.load_state_dict(torch.load(<span class="string">&quot;mod&quot;</span>))</span><br><span class="line">&lt;All keys matched successfully&gt;</span><br><span class="line"><span class="comment"># 查看导入参数后的weight的数值</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn.weight</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># PS：可以直接读取保存好的模型</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn1 = torch.load(<span class="string">&quot;mod1&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bn1</span><br><span class="line">BatchNorm2d(<span class="number">3</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h3 id="3-旧版本兼容"><a href="#3-旧版本兼容" class="headerlink" title="3.旧版本兼容"></a>3.旧版本兼容</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.nn.Module.dump_patches = <span class="literal">True</span> </span><br><span class="line"><span class="comment"># 使用时直接设定值，主要用于再导入之前版本的参数数据时，有更好的兼容性</span></span><br></pre></td></tr></table></figure>
<h3 id="4-额外状态的保存读取"><a href="#4-额外状态的保存读取" class="headerlink" title="4.额外状态的保存读取"></a>4.额外状态的保存读取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新版本功能,待使用</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>set_extra_state(state)</span><br><span class="line"><span class="comment"># 调用此函数load_state_dict()以处理在state_dict中找到的任何额外状态。如果您需要在其 state_dictget_extra_state()中存储额外的状态，请为您的模块实现此功能和对应的功能。参数：state ( dict ) -- 来自state_dict的额外状态</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>get_extra_state()</span><br><span class="line"><span class="comment"># 返回要包含在模块state_dict 中的任何额外状态。 如果您需要存储额外的状态set_extra_state()，请为您的模块实现此功能和相应功能。构建模块的state_dict()时调用此函数。</span></span><br></pre></td></tr></table></figure>
<h2 id="五-其他方法"><a href="#五-其他方法" class="headerlink" title="五.其他方法"></a>五.其他方法</h2><h3 id="1-extra-repr"><a href="#1-extra-repr" class="headerlink" title="1.extra_repr()"></a>1.extra_repr()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 该方法需要在类中自己定义,用来添加信息</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">create_net</span>(nn.Module):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="built_in">super</span>().__init__()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        self.net_model = nn.BatchNorm2d(<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        out = self.net_model(x)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="keyword">return</span> out</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">extra_repr</span>(<span class="params">self</span>):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="comment"># print(&#x27;extra_repr方法正在被调用...&#x27;)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="keyword">return</span> <span class="string">&#x27;我是用户自定义的神经网络模块...&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model = create_net()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model</span><br><span class="line">create_net(</span><br><span class="line">  我是用户自定义的神经网络模块...</span><br><span class="line">  (net_model): BatchNorm2d(<span class="number">3</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.extra_repr()</span><br><span class="line"><span class="string">&#x27;我是用户自定义的神经网络模块...&#x27;</span></span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://liumeng.top">独孤白</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://liumeng.top/link/ad092d40.html">http://liumeng.top/link/ad092d40.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://liumeng.top" target="_blank">记录收获，重拾旧遗</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/pytorch/">pytorch</a></div><div class="post_share"><div class="social-share" data-image="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/markdown/202302101913815.png" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/link/a7d413aa.html" title="typora博客书写"><img class="cover" src="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/markdown/202302102051544.png" onerror="onerror=null;src='https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">typora博客书写</div></div></a></div><div class="next-post pull-right"><a href="/link/52986632.html" title="jetson nano b01使用准备"><img class="cover" src="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/markdown/202302102041093.png" onerror="onerror=null;src='https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">jetson nano b01使用准备</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/link/e57798f6.html" title="基于Pytorch使用FFT,矩阵乘法,Conv2d计算卷积"><img class="cover" src="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/markdown/202302101913815.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-28</div><div class="title">基于Pytorch使用FFT,矩阵乘法,Conv2d计算卷积</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/img/avatar.jpg" onerror="this.onerror=null;this.src='https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">独孤白</div><div class="author-info__description">天行健 君子以自强不息</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">56</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/liumeng-hub" target="_blank" title="https://github.com/liumeng-hub"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:915738464@qq.com" target="_blank" title="915738464@qq.com"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#pytorch-nn-Module"><span class="toc-number">1.</span> <span class="toc-text">pytorch nn.Module</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E5%8F%8A%E6%95%B0%E6%8D%AE%E8%BD%AC%E7%A7%BB%E6%96%B9%E6%B3%95"><span class="toc-number">1.1.</span> <span class="toc-text">一. 数据类型转换及数据转移方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%95%B0%E6%8D%AE%E8%BD%AC%E7%A7%BBcpu-gpu"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.数据转移cpu&#x2F;gpu</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2"><span class="toc-number">1.1.2.</span> <span class="toc-text">2.数据类型转换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E9%80%9A%E7%94%A8%E6%96%B9%E6%B3%95to-args-kwargs"><span class="toc-number">1.1.3.</span> <span class="toc-text">3.通用方法to(*args, **kwargs)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C-%E6%A8%A1%E5%9E%8B%E4%BB%A5%E5%8F%8A%E7%BD%91%E7%BB%9C%E5%8F%82%E6%95%B0%E7%9A%84%E6%9F%A5%E7%9C%8B%E5%8F%8A%E8%B0%83%E6%95%B4"><span class="toc-number">1.2.</span> <span class="toc-text">二.模型以及网络参数的查看及调整</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-children%E5%92%8Cmodule"><span class="toc-number">1.2.1.</span> <span class="toc-text">1.children和module</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-buffers%E5%92%8Cparameters"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.buffers和parameters</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E5%92%8C%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9"><span class="toc-number">1.2.3.</span> <span class="toc-text">3.模型结构和数据的增删改</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%A2%AF%E5%BA%A6%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">1.2.4.</span> <span class="toc-text">4.模型与梯度初始化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E8%8E%B7%E5%8F%96%E6%8C%87%E5%AE%9A%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E7%9A%84%E5%80%BC"><span class="toc-number">1.2.5.</span> <span class="toc-text">5.获取指定模型参数的值</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89-%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83"><span class="toc-number">1.3.</span> <span class="toc-text">三.模型的训练</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%89%8D%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-number">1.3.1.</span> <span class="toc-text">1.前向和反向传播</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%92%8C%E8%AF%84%E4%BC%B0"><span class="toc-number">1.3.2.</span> <span class="toc-text">2.模型训练和评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-HOOK%E2%80%94%E2%80%94%E8%8E%B7%E5%8F%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%89%B9%E5%BE%81%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%9A%84%E6%9C%89%E6%95%88%E5%B7%A5%E5%85%B7"><span class="toc-number">1.3.3.</span> <span class="toc-text">3.HOOK——获取神经网络特征和梯度的有效工具</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B-%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E8%AF%BB%E5%8F%96"><span class="toc-number">1.4.</span> <span class="toc-text">四.模型的保存读取</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98"><span class="toc-number">1.4.1.</span> <span class="toc-text">1.模型保存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%A8%A1%E5%9E%8B%E5%8A%A0%E8%BD%BD"><span class="toc-number">1.4.2.</span> <span class="toc-text">2.模型加载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%97%A7%E7%89%88%E6%9C%AC%E5%85%BC%E5%AE%B9"><span class="toc-number">1.4.3.</span> <span class="toc-text">3.旧版本兼容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E9%A2%9D%E5%A4%96%E7%8A%B6%E6%80%81%E7%9A%84%E4%BF%9D%E5%AD%98%E8%AF%BB%E5%8F%96"><span class="toc-number">1.4.4.</span> <span class="toc-text">4.额外状态的保存读取</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94-%E5%85%B6%E4%BB%96%E6%96%B9%E6%B3%95"><span class="toc-number">1.5.</span> <span class="toc-text">五.其他方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-extra-repr"><span class="toc-number">1.5.1.</span> <span class="toc-text">1.extra_repr()</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/link/pdfaddpicture.html" title="PDF添加图片与文字"><img src="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/markdown/202312162235168.png" onerror="this.onerror=null;this.src='https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/img/404.jpg'" alt="PDF添加图片与文字"/></a><div class="content"><a class="title" href="/link/pdfaddpicture.html" title="PDF添加图片与文字">PDF添加图片与文字</a><time datetime="2023-12-26T00:00:00.000Z" title="发表于 2023-12-26 00:00:00">2023-12-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/link/topset.html" title="堆与优先队列"><img src="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/markdown/202306101159682.png" onerror="this.onerror=null;this.src='https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/img/404.jpg'" alt="堆与优先队列"/></a><div class="content"><a class="title" href="/link/topset.html" title="堆与优先队列">堆与优先队列</a><time datetime="2023-09-02T00:00:00.000Z" title="发表于 2023-09-02 00:00:00">2023-09-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/link/suixiangluday20.html" title="代码随想录(day20)"><img src="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/markdown/202306101159682.png" onerror="this.onerror=null;this.src='https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/img/404.jpg'" alt="代码随想录(day20)"/></a><div class="content"><a class="title" href="/link/suixiangluday20.html" title="代码随想录(day20)">代码随想录(day20)</a><time datetime="2023-09-01T00:00:00.000Z" title="发表于 2023-09-01 00:00:00">2023-09-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/link/paixun2.html" title="排序算法n方"><img src="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/markdown/202306101159682.png" onerror="this.onerror=null;this.src='https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/img/404.jpg'" alt="排序算法n方"/></a><div class="content"><a class="title" href="/link/paixun2.html" title="排序算法n方">排序算法n方</a><time datetime="2023-09-01T00:00:00.000Z" title="发表于 2023-09-01 00:00:00">2023-09-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/link/paixunlogn.html" title="排序算法nlogn"><img src="https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/markdown/202306101159682.png" onerror="this.onerror=null;this.src='https://liumeng-blog.oss-cn-hangzhou.aliyuncs.com/img/404.jpg'" alt="排序算法nlogn"/></a><div class="content"><a class="title" href="/link/paixunlogn.html" title="排序算法nlogn">排序算法nlogn</a><time datetime="2023-09-01T00:00:00.000Z" title="发表于 2023-09-01 00:00:00">2023-09-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 By liumeng</div><div class="framework-info"><span>小破站正在安全运行 </span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"><use id="modeicon" xlink:href="#icon-moon"></use></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'nemsAMaYAJs1jMlB2Gqa1lCI-MdYXbMMI',
      appKey: '96YIeaSpipct4pRmJ7Kt8r5O',
      avatar: 'monsterid',
      serverURLs: 'https://server.liumeng.top',
      emojiMaps: "",
      path: window.location.pathname,
      master: 'bc41b72793c99baf4f681cf457f64ec1',
      tagMeta: ["博主","小伙伴","访客"],
      friends: [],
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('/js/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script src="/js/jquery.js" async></script><script src="/js/foot.js" async></script><script src="http://cdn.bootcss.com/pace/1.0.2/pace.min.js" async></script><script src="/js/sun_moon.js" async></script><script src="/js/nav.js" async></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>